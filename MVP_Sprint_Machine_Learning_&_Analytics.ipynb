{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO6DY1nF2WA0SNJ4BICBsQO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luizthompson/MVP_Sprints/blob/main/MVP_Sprint_Machine_Learning_%26_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVP - Sprint: Machine Learning & Analytics\n",
        "Luiz Guilherme Thompson Vaz\n"
      ],
      "metadata": {
        "id": "wiRfIdnOVS82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição do Problema\n",
        "\n",
        "Descrição do Problema:\n",
        "O problema em questão é analisar os resultados de partidas da Copa Libertadores da América, considerando informações como a edição do torneio, a rodada, a data da partida, os clubes envolvidos e os placares."
      ],
      "metadata": {
        "id": "SdO7_jk5WGS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Premissas ou Hipóteses\n",
        "\n",
        "\n",
        "Os resultados das partidas refletem o desempenho das equipes.\n",
        "As características dos clubes (força, estratégias, histórico, etc.) influenciam os resultados.\n",
        "O formato do torneio permaneceu constante ao longo das edições analisadas."
      ],
      "metadata": {
        "id": "A-2BkkUMWmVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restrições ou Condições para Selecionar os Dados\n",
        "\n",
        "Os dados devem ser confiáveis e abranger várias edições da Copa Libertadores.\n",
        "Os dados devem conter informações relevantes para análise, como os clubes envolvidos, as datas e os placares das partidas."
      ],
      "metadata": {
        "id": "4vxDObtSWue1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descrição do Dataset\n",
        "O dataset consiste em um conjunto de dados tabulares com as seguintes colunas:\n",
        "\n",
        "Edition: Ano da edição da Copa Libertadores.\n",
        "Round: Rodada da partida (ex: Final, Semifinal, Quartas de Final, etc.).\n",
        "Date: Data da partida.\n",
        "Home Club: Clube mandante.\n",
        "Away Club: Clube visitante.\n",
        "Home Score: Placar do clube mandante.\n",
        "Away Score: Placar do clube visitante.\n"
      ],
      "metadata": {
        "id": "aqfHpSQkW26O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Loading the dataset\n",
        "url = 'https://raw.githubusercontent.com/luizthompson/MVP_Sprints/8dd5432382946862109f439d0a49642b781a45e7/libertadores-results-ds.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Displaying the first few rows of the dataset\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp8Yo936YlMF",
        "outputId": "2e5ff6e8-f5d1-415c-87d0-054e24f83ba2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Edition      Round        Date      Home Club      Away Club  Home Score  \\\n",
            "0     2023      Final   4/11/2023  Fluminense FC   Boca Juniors           2   \n",
            "1     2023  Semifinal   6/10/2023      Palmeiras   Boca Juniors           1   \n",
            "2     2023  Semifinal   5/10/2023  Internacional  Fluminense FC           1   \n",
            "3     2023  Semifinal  29/09/2023   Boca Juniors      Palmeiras           0   \n",
            "4     2023  Semifinal  28/09/2023  Fluminense FC  Internacional           2   \n",
            "\n",
            "   AwayScore  \n",
            "0          1  \n",
            "1          1  \n",
            "2          2  \n",
            "3          0  \n",
            "4          2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação de Dados\n",
        "\n",
        "Separação do Dataset\n",
        "O dataset pode ser separado em conjuntos de treino e teste, onde os dados de uma determinada edição podem ser utilizados para treino e os dados de uma edição posterior podem ser usados para teste.\n"
      ],
      "metadata": {
        "id": "HTbh4QlcW_29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into train and test\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Size of training set: {len(train)}')\n",
        "print(f'Size of testing set: {len(test)}')"
      ],
      "metadata": {
        "id": "G9aH8R7kXr_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f0f48a-07fb-43ce-8619-163b870ea67c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training set: 1456\n",
            "Size of testing set: 365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validação Cruzada\n",
        "Neste caso, temos um conjunto de dados de tamanho razoável (1456 amostras de treinamento e 365 amostras de teste). Isso é suficiente para treinar nosso modelo e ter uma estimativa confiável de seu desempenho em dados não vistos.Dado o tamanho do nosso conjunto de dados, a divisão única de treinamento/teste que estamos usando deve fornecer uma avaliação suficientemente precisa do desempenho do nosso modelo.Portanto, decidimos não usar a validação cruzada neste projeto para economizar recursos computacionais sem sacrificar a precisão da nossa avaliação do modelo.\n"
      ],
      "metadata": {
        "id": "WJdHQIzEYE2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformações de Dados\n",
        "\n",
        "Neste caso, foi realizado duas transformações principais:\n",
        "\n",
        "1)Codificação One-Hot: As variáveis categóricas no conjunto de dados, que podem incluir características como o round do jogo e os clubes em casa e fora, são transformadas em uma forma que pode ser fornecida aos algoritmos de machine learning para melhorar a precisão das previsões. A codificação one-hot é um processo pelo qual variáveis categóricas são convertidas em uma forma que poderia ser fornecida aos algoritmos de ML para melhorar a precisão das previsões.\n",
        "2)Padronização: Após a codificação one-hot, as variáveis numéricas são padronizadas para terem média 0 e desvio padrão 1. Isso é especialmente importante para os placares das partidas, garantindo que eles estejam na mesma escala e não distorçam o modelo\n"
      ],
      "metadata": {
        "id": "S3yPmiLBYMpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Carregando o conjunto de dados\n",
        "url = 'https://raw.githubusercontent.com/luizthompson/MVP_Sprints/8dd5432382946862109f439d0a49642b781a45e7/libertadores-results-ds.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Separando as variáveis categóricas\n",
        "cat_vars = df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Aplicando a codificação one-hot nas variáveis categóricas\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "encoded_vars = encoder.fit_transform(df[cat_vars])\n",
        "\n",
        "# Criando um DataFrame com as variáveis codificadas\n",
        "encoded_df = pd.DataFrame(encoded_vars, columns=encoder.get_feature_names_out(cat_vars))\n",
        "\n",
        "# Removendo as variáveis categóricas originais do DataFrame\n",
        "df.drop(columns=cat_vars, inplace=True)\n",
        "\n",
        "# Concatenando o DataFrame original com o DataFrame codificado\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "# Agora, vamos padronizar as variáveis numéricas\n",
        "scaler = StandardScaler()\n",
        "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n"
      ],
      "metadata": {
        "id": "gYXglbDaYOgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbde632-67c4-47c6-9454-330af9542a18"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelagem e Treinamento\n",
        "\n",
        "1.  Seleção do algoritmo - Foi usado o algoritmo Random Forest Regressor ele é baseado em árvores de decisão e funciona criando um “floresta” de árvores de decisão independentes durante o treinamento e produzindo a média das previsões produzidas pelas árvores individuais.\n",
        "\n",
        "2.  Ajuste inicial dos hiperparâmetros: Inicialmente, vamos usar os hiperparâmetros padrão fornecidos pela implementação do RandomForestRegressor no sklearn. Isso inclui o uso de um número de estimadores (árvores de decisão) igual a 100.\n",
        "\n",
        "3.  Treinamento do modelo: Vamos treinar o modelo usando o conjunto de treinamento. Se o modelo estiver sofrendo de underfitting (ou seja, não está se ajustando bem nem mesmo aos dados de treinamento), podemos tentar aumentar a complexidade do modelo, por exemplo, aumentando o número de estimadores ou reduzindo o parâmetro de regularização.\n",
        "\n",
        "4.  Otimização dos hiperparâmetros: Se necessário, podemos otimizar os hiperparâmetros do modelo usando técnicas como a pesquisa em grade (GridSearch) ou a pesquisa aleatória (RandomSearch). Isso envolve a experimentação de diferentes combinações de hiperparâmetros para encontrar a combinação que produz o melhor desempenho no conjunto de validação.\n",
        "\n",
        "5.  Métodos avançados: Dependendo do desempenho do nosso modelo inicial, podemos considerar o uso de métodos mais avançados ou complexos. Isso pode incluir o uso de diferentes algoritmos de aprendizado de máquina, a criação de um comitê de modelos (ensemble), ou o uso de técnicas de aprendizado profundo.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ptgu5j1JdPHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Definindo o modelo\n",
        "reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Treinando o modelo\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# Avaliando o modelo\n",
        "print(f'Erro Quadrático Médio: {mean_squared_error(y_test, y_pred)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJl9WKYWd4bV",
        "outputId": "2aaca904-bab6-48ab-cb35-42b692be478a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro Quadrático Médio: 0.16599215554281552\n"
          ]
        }
      ]
    }
  ]
}