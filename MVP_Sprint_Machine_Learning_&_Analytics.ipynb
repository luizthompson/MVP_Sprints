{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPAVwnbq2Yn3mx3i1qzeZ+a",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luizthompson/MVP_Sprints/blob/main/MVP_Sprint_Machine_Learning_%26_Analytics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MVP - Sprint: Machine Learning & Analytics\n",
        "Luiz Guilherme Thompson Vaz\n"
      ],
      "metadata": {
        "id": "wiRfIdnOVS82"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Definição do Problema\n",
        "\n",
        "Descrição do Problema:\n",
        "O problema em questão é analisar os resultados de partidas da Copa Libertadores da América, considerando informações como a edição do torneio, a rodada, a data da partida, os clubes envolvidos e os placares."
      ],
      "metadata": {
        "id": "SdO7_jk5WGS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Premissas ou Hipóteses\n",
        "\n",
        "\n",
        "Os resultados das partidas refletem o desempenho das equipes.\n",
        "As características dos clubes (força, estratégias, histórico, etc.) influenciam os resultados.\n",
        "O formato do torneio permaneceu constante ao longo das edições analisadas."
      ],
      "metadata": {
        "id": "A-2BkkUMWmVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Restrições ou Condições para Selecionar os Dados\n",
        "\n",
        "Os dados são confiáveis e abrangem várias edições da Copa Libertadores.\n",
        "Os dados contém informações relevantes para análise, como os clubes envolvidos, as datas e os placares das partidas."
      ],
      "metadata": {
        "id": "4vxDObtSWue1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descrição do Dataset\n",
        "O dataset consiste em um conjunto de dados tabulares com as seguintes colunas:\n",
        "\n",
        "Edition: Ano da edição da Copa Libertadores.\n",
        "Round: Rodada da partida (ex: Final, Semifinal, Quartas de Final, etc.).\n",
        "Date: Data da partida.\n",
        "Home Club: Clube mandante.\n",
        "Away Club: Clube visitante.\n",
        "Home Score: Placar do clube mandante.\n",
        "Away Score: Placar do clube visitante.\n"
      ],
      "metadata": {
        "id": "aqfHpSQkW26O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Carregar o dataset\n",
        "url = 'https://raw.githubusercontent.com/luizthompson/MVP_Sprints/8dd5432382946862109f439d0a49642b781a45e7/libertadores-results-ds.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Exibindo as primeiras linhas do dataset\n",
        "print(df.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp8Yo936YlMF",
        "outputId": "990f3873-83fe-4756-82db-5e4ed5bbf4ac"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Edition      Round        Date      Home Club      Away Club  Home Score  \\\n",
            "0     2023      Final   4/11/2023  Fluminense FC   Boca Juniors           2   \n",
            "1     2023  Semifinal   6/10/2023      Palmeiras   Boca Juniors           1   \n",
            "2     2023  Semifinal   5/10/2023  Internacional  Fluminense FC           1   \n",
            "3     2023  Semifinal  29/09/2023   Boca Juniors      Palmeiras           0   \n",
            "4     2023  Semifinal  28/09/2023  Fluminense FC  Internacional           2   \n",
            "\n",
            "   AwayScore  \n",
            "0          1  \n",
            "1          1  \n",
            "2          2  \n",
            "3          0  \n",
            "4          2  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preparação de Dados\n",
        "\n",
        "Separação do Dataset\n",
        "O dataset pode ser separado em conjuntos de treino e teste, onde os dados de uma determinada edição podem ser utilizados para treino e os dados de uma edição posterior podem ser usados para teste.\n"
      ],
      "metadata": {
        "id": "HTbh4QlcW_29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into train and test\n",
        "train, test = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f'Size of training set: {len(train)}')\n",
        "print(f'Size of testing set: {len(test)}')"
      ],
      "metadata": {
        "id": "G9aH8R7kXr_v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f0f48a-07fb-43ce-8619-163b870ea67c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training set: 1456\n",
            "Size of testing set: 365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Validação Cruzada\n",
        "Neste caso, temos um conjunto de dados de tamanho razoável (1456 amostras de treinamento e 365 amostras de teste). Isso é suficiente para treinar nosso modelo e ter uma estimativa confiável de seu desempenho em dados não vistos.Dado o tamanho do nosso conjunto de dados, a divisão única de treinamento/teste que estamos usando deve fornecer uma avaliação suficientemente precisa do desempenho do nosso modelo.Portanto, decidimos não usar a validação cruzada neste projeto para economizar recursos computacionais sem sacrificar a precisão da nossa avaliação do modelo.\n"
      ],
      "metadata": {
        "id": "WJdHQIzEYE2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformações de Dados\n",
        "\n",
        "Neste caso, foi realizado duas transformações principais:\n",
        "\n",
        "1. Codificação One-Hot: As variáveis categóricas no conjunto de dados, que podem incluir características como o round do jogo e os clubes em casa e fora, são transformadas em uma forma que pode ser fornecida aos algoritmos de machine learning para melhorar a precisão das previsões. A codificação one-hot é um processo pelo qual variáveis categóricas são convertidas em uma forma que poderia ser fornecida aos algoritmos de ML para melhorar a precisão das previsões.\n",
        "\n",
        "2. Padronização: Após a codificação one-hot, as variáveis numéricas são padronizadas para terem média 0 e desvio padrão 1. Isso é especialmente importante para os placares das partidas, garantindo que eles estejam na mesma escala e não distorçam o modelo"
      ],
      "metadata": {
        "id": "S3yPmiLBYMpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Carregando o conjunto de dados\n",
        "url = 'https://raw.githubusercontent.com/luizthompson/MVP_Sprints/8dd5432382946862109f439d0a49642b781a45e7/libertadores-results-ds.csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Separando as variáveis categóricas\n",
        "cat_vars = df.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "# Aplicando a codificação one-hot nas variáveis categóricas\n",
        "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
        "encoded_vars = encoder.fit_transform(df[cat_vars])\n",
        "\n",
        "# Criando um DataFrame com as variáveis codificadas\n",
        "encoded_df = pd.DataFrame(encoded_vars, columns=encoder.get_feature_names_out(cat_vars))\n",
        "\n",
        "# Removendo as variáveis categóricas originais do DataFrame\n",
        "df.drop(columns=cat_vars, inplace=True)\n",
        "\n",
        "# Concatenando o DataFrame original com o DataFrame codificado\n",
        "df = pd.concat([df, encoded_df], axis=1)\n",
        "\n",
        "# Agora, vamos padronizar as variáveis numéricas\n",
        "scaler = StandardScaler()\n",
        "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n"
      ],
      "metadata": {
        "id": "gYXglbDaYOgd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fbde632-67c4-47c6-9454-330af9542a18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelagem e Treinamento\n",
        "\n",
        "1.  Seleção do algoritmo - Foi usado o algoritmo Random Forest Regressor ele é baseado em árvores de decisão e funciona criando um “floresta” de árvores de decisão independentes durante o treinamento e produzindo a média das previsões produzidas pelas árvores individuais.\n",
        "\n",
        "2.  Ajuste inicial dos hiperparâmetros: Inicialmente, vamos usar os hiperparâmetros padrão fornecidos pela implementação do RandomForestRegressor no sklearn. Isso inclui o uso de um número de estimadores (árvores de decisão) igual a 100.\n",
        "\n",
        "3.  Treinamento do modelo: Vamos treinar o modelo usando o conjunto de treinamento. Se o modelo estiver sofrendo de underfitting (ou seja, não está se ajustando bem nem mesmo aos dados de treinamento), podemos tentar aumentar a complexidade do modelo, por exemplo, aumentando o número de estimadores ou reduzindo o parâmetro de regularização.\n",
        "\n",
        "4.  Otimização dos hiperparâmetros: Se necessário, podemos otimizar os hiperparâmetros do modelo usando técnicas como a pesquisa em grade (GridSearch) ou a pesquisa aleatória (RandomSearch). Isso envolve a experimentação de diferentes combinações de hiperparâmetros para encontrar a combinação que produz o melhor desempenho no conjunto de validação.\n",
        "\n",
        "5.  Métodos avançados: Dependendo do desempenho do nosso modelo inicial, podemos considerar o uso de métodos mais avançados ou complexos. Isso pode incluir o uso de diferentes algoritmos de aprendizado de máquina, a criação de um comitê de modelos (ensemble), ou o uso de técnicas de aprendizado profundo.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ptgu5j1JdPHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Definindo o modelo\n",
        "reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Treinando o modelo\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# Avaliando o modelo\n",
        "print(f'Erro Quadrático Médio: {mean_squared_error(y_test, y_pred)}')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJl9WKYWd4bV",
        "outputId": "2aaca904-bab6-48ab-cb35-42b692be478a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro Quadrático Médio: 0.16599215554281552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliação de Resultados\n",
        "\n",
        "1. Neste caso, estamos usando o EQM, que é uma métrica comum para avaliar modelos de regressão. O EQM mede a média dos erros quadrados entre as previsões e os valores reais.\n",
        "\n",
        "2. Treinamento e teste do modelo: O modelo foi treinado com toda a base de treino e testado com a base de teste. Isso é importante para avaliar como o modelo se comporta com dados não vistos.\n",
        "\n",
        "3. Análise dos resultados: Com base no EQM obtido, podemos dizer que o modelo tem um desempenho razoável, embora a interpretação do EQM dependa muito do contexto e da escala dos seus dados.\n",
        "\n",
        "4. Comparação de modelos: No momento, temos apenas um modelo, o RandomForestRegressor. Se tivéssemos mais modelos, poderíamos comparar o EQM de cada modelo para escolher o melhor.\n",
        "\n",
        "5. Melhor solução encontrada: AA melhor solução encontrada até agora é o modelo RandomForestRegressor com os hiperparâmetros padrão.\n",
        "\n",
        "6. Como o desempenho do modelo no conjunto de treinamento e no conjunto de teste é semelhante, não há indicações claras de overfitting. Overfitting ocorre quando um modelo se ajusta muito bem aos dados de treinamento, mas não generaliza bem para novos dados. No entanto, sem mais informações, como o desempenho do modelo no conjunto de treinamento, não podemos confirmar se há overfitting.\n"
      ],
      "metadata": {
        "id": "TwzlfliJU_YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Definindo o modelo\n",
        "reg = RandomForestRegressor(random_state=42)\n",
        "\n",
        "# Treinando o modelo com toda a base de treino\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Testando o modelo com a base de teste\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# Avaliando o modelo\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Erro Quadrático Médio: {mse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBHVzQ_kVCju",
        "outputId": "5779939d-2405-4f6b-db1e-6424e37ee954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro Quadrático Médio: 0.16599215554281552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando as bibliotecas necessárias\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Definindo o modelo\n",
        "reg = LinearRegression()\n",
        "\n",
        "# Treinando o modelo\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Fazendo previsões no conjunto de teste\n",
        "y_pred = reg.predict(X_test)\n",
        "\n",
        "# Avaliando o modelo\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f'Erro Quadrático Médio para a Regressão Linear: {mse}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mvq6IvKagIB",
        "outputId": "d5cf3d57-bf9d-4a46-f158-76f0bd698855"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Erro Quadrático Médio para a Regressão Linear: 31.015735397380652\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tS7T6rsYaf2p"
      }
    }
  ]
}